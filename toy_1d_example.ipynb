{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "toy_1d_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobby-he/bayesian-ntk/blob/master/toy_1d_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2ELyx-Xyo1w",
        "colab_type": "text"
      },
      "source": [
        "### Imports and plot utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKnlmcY9eQJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "both",
        "outputId": "ed71e05f-20c0-49f3-c024-ff0e1dc61cd0"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "user = getpass('GitHub user')\n",
        "password = getpass('GitHub password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "!git clone https://$GITHUB_AUTH@github.com/bobby-he/bayesian-ntk.git\n",
        "%cd bayesian-ntk/bayesian_ntk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-caa6ab63af82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgetpass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GitHub user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GitHub password'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GITHUB_AUTH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcmXyerpgolH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q git+https://www.github.com/google/neural-tangents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKMmriLHd7a0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "from jax import random\n",
        "from jax import vmap\n",
        "\n",
        "import functools\n",
        "\n",
        "from utils import get_toy_data\n",
        "from models import homoscedastic_model\n",
        "from train import train_model\n",
        "import predict\n",
        "import config\n",
        "\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('pdf', 'svg')\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=1.3)\n",
        "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".95\"})\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0rHIC0sd7a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_plot(x=None, y=None):\n",
        "    ax = plt.gca()\n",
        "    if x is not None:\n",
        "        plt.xlabel(x, fontsize=20)\n",
        "    if y is not None:\n",
        "        plt.ylabel(y, fontsize=20)\n",
        "\n",
        "def finalize_plot(shape=(1, 1)):\n",
        "    plt.gcf().set_size_inches(\n",
        "        shape[0] * 1.5 * plt.gcf().get_size_inches()[1],\n",
        "        shape[1] * 1.5 * plt.gcf().get_size_inches()[1])\n",
        "    plt.tight_layout()\n",
        "    \n",
        "def plot_fn(train, test, *fs):\n",
        "    train_xs, train_ys = train\n",
        "\n",
        "    plt.plot(train_xs, train_ys, 'go', markersize=7, label='train')\n",
        "\n",
        "    if test != None:\n",
        "        test_xs, test_ys = test\n",
        "        plt.plot(test_xs, test_ys, 'k--', linewidth=3, label='$y=x\\mathrm{sin}(x)$')\n",
        "\n",
        "        for f in fs:\n",
        "            plt.plot(test_xs, f(test_xs), '-', linewidth=3)\n",
        "    plt.xlim([-6., 6.])\n",
        "    plt.ylim([-6., 6.])\n",
        "    format_plot('$x$', '$y$')\n",
        "    plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gm3Ij58y0QM",
        "colab_type": "text"
      },
      "source": [
        "# Toy 1d example notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEmjx3wIy-x9",
        "colab_type": "text"
      },
      "source": [
        "The purpose of this notebook will be to demonstrate how to train Bayesian Deep Ensembles as described in our NeurIPS 2020 submission 'Bayesian Deep Ensembles via the Neural Tangent Kernel', using our provided package: `bayesian-ntk`. We will do this by going through the toy homoscedastic regression example from our submission: . The package builds on top of the [Neural Tangents](https://github.com/google/neural-tangents) library in [JAX](https://github.com/google/jax)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP4gRsJp0fFt",
        "colab_type": "text"
      },
      "source": [
        "The package stores default config files in `bayesian_ntk.config.py`. For example, our default NN baselearner models will have the following config:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EEGEgRzd7bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_config = config.get_model_config('default')\n",
        "print(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekm5Wwn7LF0-",
        "colab_type": "text"
      },
      "source": [
        "We can now use Neural Tangents to return a `kernel_fn` function that calculates the analytic NTK & NNGP kernels for an infinite width version of the NN corresponding to our `model_config` under NTK parameterisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd2JZjizd7bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, _, kernel_fn = homoscedastic_model(parameterization = 'ntk', **model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOEcb-lld7bQ",
        "colab_type": "text"
      },
      "source": [
        "Next we generate our training and test data, using the same `key` as in the paper for reproducibility. Note that `get_toy_data` returns noisy version of the train labels, in line with Lemma 3 of [Osband et al](https://papers.nips.cc/paper/8080-randomized-prior-functions-for-deep-reinforcement-learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uQ3Fc5Dd7bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key = random.PRNGKey(10)\n",
        "data_config = config.get_data_config('default')\n",
        "train_data, test_data = get_toy_data(key, config.NOISE_SCALE, **data_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-CzOlvSRQwB",
        "colab_type": "text"
      },
      "source": [
        "Let's visualise our train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS77cTB7d7bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_fn(train_data, test_data)\n",
        "finalize_plot((1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke-R3nI-bVJ5",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEWT__PdThz0",
        "colab_type": "text"
      },
      "source": [
        "`bayesian_ntk.predict` is a stripped down version of [neural_tangents.predict](https://github.com/google/neural-tangents/blob/master/neural_tangents/predict.py) with a few differences: including functionality to calculate the NTKGP posterior, as well as ability to model observation noise. Of course we won't be able to use this for larger datasets, but for our toy example we can calculate the analytic NTKGP and NNGP posteriors (with observation noise), which we shall show below, storing results in `predictions`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqXuhSzVd7bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analytic_ntkgp_moments, analytic_nngp_moments = predict.gp_inference(\n",
        "    kernel_fn = kernel_fn,\n",
        "    x_train = train_data.inputs,\n",
        "    y_train = train_data.labels,\n",
        "    x_test = test_data.inputs,\n",
        "    get = ['ntk', 'nngp'],\n",
        "    diag_reg = config.NOISE_SCALE**2,\n",
        "    compute_cov = True\n",
        ")\n",
        "\n",
        "predictions = {\n",
        "    'NTKGP analytic': analytic_ntkgp_moments,\n",
        "    'NNGP analytic': analytic_nngp_moments\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFEII1YZd7bj",
        "colab_type": "text"
      },
      "source": [
        "##### Before we plot our results, we need to train our ensembles for each ensemble `train_method`: deep ensemble, RP-param and NTKGP-param. We will use the `vmap` function in JAX to distribute the baselearner training function `train_model` into one ensemble training function `train_ensemble`. \n",
        "\n",
        "The modified forward passes and different regularisation functions for each ensemble `train_method` can be found in `bayesian_ntk.train_util`, and are called within `train_model`. \n",
        "\n",
        "We aggregate ensemble predictions in `predictions` as for the analytic posteriors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0uFaBnxd7bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_config = config.get_train_config('default')\n",
        "ensemble_key = random.split(key, config.ENSEMBLE_SIZE)\n",
        "train_baselearner = lambda key, train_method: train_model(key, train_method, train_data, test_data, parameterization = 'standard', **train_config)\n",
        "train_ensemble = lambda train_method: vmap(train_baselearner, (0, None))(ensemble_key, train_method)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKXl1hOhi5gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble_methods_list = ['Deep ensemble', 'RP-param', 'NTKGP-param']\n",
        "\n",
        "for method in ensemble_methods_list:\n",
        "    method_input_str = config.method_input_dict[method]\n",
        "    print(f\"Starting ensemble training for {method} method\")\n",
        "    baselearners_test_pred = train_ensemble(method_input_str)\n",
        "    ensemble_mean = np.mean(baselearners_test_pred, axis = 0).reshape(-1,)\n",
        "    ensemble_var = np.var(baselearners_test_pred, axis = 0, ddof = 1).reshape(-1,)\n",
        "    ensemble_std = np.sqrt(ensemble_var + config.NOISE_SCALE ** 2)\n",
        "    predictions.update(\n",
        "        {\n",
        "            method: config.Gaussian(ensemble_mean, ensemble_std)\n",
        "        }\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoEOTvE1d7b0",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title ##### Finally, we can plot `predictions` for the different analytic posterior and ensmeble methods, reproducing the Figure 1 from our paper. \n",
        "plot_method_list = ['NNGP analytic'] + ensemble_methods_list\n",
        "legend = functools.partial(plt.legend, fontsize=8.5)\n",
        "for plt_idx in range(1, 5):\n",
        "    plt.subplot(1, 4, plt_idx)\n",
        "    plot_fn(train_data, test_data)\n",
        "    \n",
        "    ntkgp_moments = predictions['NTKGP analytic']\n",
        "    ntkgp_means = ntkgp_moments.mean\n",
        "    ntkgp_stds = ntkgp_moments.standard_deviation\n",
        "    plt.plot(test_data.inputs, ntkgp_means, 'r-', linewidth = 3, alpha = 0.5)\n",
        "    plt.fill_between(\n",
        "        np.reshape(test_data.inputs, (-1,)),\n",
        "        ntkgp_means - 2 * ntkgp_stds,\n",
        "        ntkgp_means + 2 * ntkgp_stds,\n",
        "        color='r',\n",
        "        alpha = 0.3\n",
        "    )\n",
        "    method = plot_method_list[plt_idx - 1]\n",
        "    method_moments = predictions[method]\n",
        "    method_means = method_moments.mean\n",
        "    method_stds = method_moments.standard_deviation\n",
        "    plt.plot(test_data.inputs, method_means, 'b-', linewidth = 2, alpha = 0.5)\n",
        "    plt.fill_between(\n",
        "        np.reshape(test_data.inputs, (-1,)),\n",
        "        method_means - 2 * method_stds,\n",
        "        method_means + 2 * method_stds,\n",
        "        color='b',\n",
        "        alpha = 0.3\n",
        "    )\n",
        "    \n",
        "    legend(['Train', 'Test', 'NTKGP analytic', method], loc = 'upper left')\n",
        "    plt.xlim([-6., 6.])\n",
        "    plt.ylim([-6., 6.])\n",
        "    format_plot('$x$', '$f$')\n",
        "finalize_plot((4,1))\n",
        "#     plt.plot(test_data.inputs, )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}